{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07768fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 10:08:01.703266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-23 10:08:01.703295: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# import transformers\n",
    "import re\n",
    "from string import punctuation\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForMaskedLM\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fa3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '!\"#$%&\\'()*+,-./:;<=>?@\\\\^_`{|}~“”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8118707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(f\"[{re.escape(punctuation)}] \", \"\", text)  # Remove punctuation\n",
    "    text = \" \".join(text.split())  # Remove extra spaces, tabs, and new lines\n",
    "    return text\n",
    "\n",
    "def mask_tokens(mask_with, text):\n",
    "    tokens = text.split(\" [break] \")\n",
    "    tokens.pop(1)\n",
    "    masked = \" [MASK] \".join(tokens)\n",
    "    return masked\n",
    "\n",
    "\n",
    "def no_masks(mask_with, text):\n",
    "    tokens = text.split(\" [break] \")\n",
    "    tokens.pop(1)\n",
    "    masked = \" \".join(tokens)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc05df8",
   "metadata": {},
   "source": [
    "### Load date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7e7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"/scratch/venia/web2wiki/data/tag_info_clean4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111d319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101c0951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243630\n"
     ]
    }
   ],
   "source": [
    "dff = dff.dropna(subset=[\"nbhd_text\"])\n",
    "print(len(dff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457097a7",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476f0cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230268\n"
     ]
    }
   ],
   "source": [
    "dff[\"clean_text\"]=dff[\"nbhd_text\"].apply(lambda x: preprocess_text(str(x)))\n",
    "dff = dff[dff[\"clean_text\"].apply(lambda x: x.split(\" [break] \")).map(len)>1]\n",
    "dff[\"masked_text\"] = dff[[\"clean_text\",\"order\"]].apply(lambda x: no_masks(x[\"order\"], x[\"clean_text\"]),axis = 1)\n",
    "print(len(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b84d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.groupby(\"order\").sample(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325256f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"label\"] = dff[\"order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac7166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dff[[\"masked_text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c23d79",
   "metadata": {},
   "source": [
    "### BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb55a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccda08ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e5514cf04c40b98334dc0e106e263f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# taken from https://huggingface.co/docs/transformers/training \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"masked_text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = data.map(tokenize_function, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9678804d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d75c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "374aa5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f13871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", num_train_epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10cbaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets.shuffle().select(range(2000))\n",
    "small_eval_dataset = tokenized_datasets.shuffle().select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfbadb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41514c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45cd3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3).to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c21e1f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_init(),\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05d4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e5850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: masked_text, __index_level_0__. If masked_text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/veselovs/miniconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2000\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f9d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75740eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(small_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58473217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d80134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8ec1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4b02b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object get_gpus.<locals>.<genexpr> at 0x7fcde3c48270>\n",
      "<itertools.compress object at 0x7fcde48d4b50>\n",
      "[pid: 2601588 | gpu_id: 0 | gpu_uuid: GPU-179d8d48-4435-e86c-4611-e43a88080f06 | gpu_name: NVIDIA GeForce GTX TITAN X | used_memory:  3155.0MB, pid: 2606488 | gpu_id: 0 | gpu_uuid: GPU-179d8d48-4435-e86c-4611-e43a88080f06 | gpu_name: NVIDIA GeForce GTX TITAN X | used_memory:  4469.0MB, pid: 2607300 | gpu_id: 0 | gpu_uuid: GPU-179d8d48-4435-e86c-4611-e43a88080f06 | gpu_name: NVIDIA GeForce GTX TITAN X | used_memory:  4574.0MB, pid: 2601588 | gpu_id: 1 | gpu_uuid: GPU-2fe93d96-0028-4a24-1f2b-01c7d0332ce7 | gpu_name: NVIDIA GeForce GTX TITAN X | used_memory:  1101.0MB, pid: 2606488 | gpu_id: 1 | gpu_uuid: GPU-2fe93d96-0028-4a24-1f2b-01c7d0332ce7 | gpu_name: NVIDIA GeForce GTX TITAN X | used_memory:   212.0MB, pid: 2607300 | gpu_id: 1 | gpu_uuid: GPU-2fe93d96-0028-4a24-1f2b-01c7d0332ce7 | gpu_name: NVIDIA GeForce GTX TITAN X | used_memory:   212.0MB]\n"
     ]
    }
   ],
   "source": [
    "import nvsmi\n",
    "\n",
    "print(nvsmi.get_gpus())\n",
    "print(nvsmi.get_available_gpus())\n",
    "print(nvsmi.get_gpu_processes())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ab1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
